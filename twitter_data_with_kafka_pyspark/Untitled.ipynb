{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5237bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in /home/rita/anaconda3/lib/python3.9/site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "829623ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "from ast import literal_eval\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6af306b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 15:59:24,174.174.82542991638184:kafka.conn:140038448103808:INFO:79740:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: connecting to localhost:9092 [('127.0.0.1', 9092) IPv4]\n",
      "2022-01-06 15:59:24,177.177.41131782531738:kafka.conn:140038448103808:INFO:79740:Probing node bootstrap-0 broker version\n",
      "2022-01-06 15:59:24,179.179.00466918945312:kafka.conn:140038448103808:INFO:79740:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: Connection complete.\n",
      "2022-01-06 15:59:24,283.283.5407257080078:kafka.conn:140038448103808:INFO:79740:Broker version identified as 2.5.0\n",
      "2022-01-06 15:59:24,285.285.2325439453125:kafka.conn:140038448103808:INFO:79740:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup\n",
      "2022-01-06 15:59:24,286.286.73458099365234:kafka.coordinator.consumer:140038448103808:WARNING:79740:group_id is None: disabling auto-commit.\n",
      "2022-01-06 15:59:24,288.288.0709171295166:kafka.consumer.subscription_state:140038448103808:INFO:79740:Updating subscribed topics to: ('trump',)\n",
      "2022-01-06 15:59:24,291.291.0923957824707:kafka.consumer.subscription_state:140038448103808:INFO:79740:Updated partition assignment: [TopicPartition(topic='trump', partition=0)]\n",
      "2022-01-06 15:59:24,293.293.2615280151367:kafka.conn:140038448103808:INFO:79740:<BrokerConnection node_id=0 host=EMPID21092:9092 <connecting> [IPv4 ('127.0.1.1', 9092)]>: connecting to EMPID21092:9092 [('127.0.1.1', 9092) IPv4]\n",
      "2022-01-06 15:59:24,294.294.19803619384766:kafka.conn:140038448103808:INFO:79740:<BrokerConnection node_id=0 host=EMPID21092:9092 <connecting> [IPv4 ('127.0.1.1', 9092)]>: Connection complete.\n",
      "2022-01-06 15:59:24,295.295.3019142150879:kafka.conn:140038448103808:INFO:79740:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: Closing connection. \n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/rita/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3444\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"/tmp/ipykernel_79740/2898281408.py\"\u001b[0m, line \u001b[1;32m3\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    for message in consumer:\n",
      "  File \u001b[1;32m\"/home/rita/anaconda3/lib/python3.9/site-packages/kafka/consumer/group.py\"\u001b[0m, line \u001b[1;32m1193\u001b[0m, in \u001b[1;35m__next__\u001b[0m\n    return self.next_v2()\n",
      "  File \u001b[1;32m\"/home/rita/anaconda3/lib/python3.9/site-packages/kafka/consumer/group.py\"\u001b[0m, line \u001b[1;32m1201\u001b[0m, in \u001b[1;35mnext_v2\u001b[0m\n    return next(self._iterator)\n",
      "  File \u001b[1;32m\"/home/rita/anaconda3/lib/python3.9/site-packages/kafka/consumer/group.py\"\u001b[0m, line \u001b[1;32m1116\u001b[0m, in \u001b[1;35m_message_generator_v2\u001b[0m\n    record_map = self.poll(timeout_ms=timeout_ms, update_offsets=False)\n",
      "  File \u001b[1;32m\"/home/rita/anaconda3/lib/python3.9/site-packages/kafka/consumer/group.py\"\u001b[0m, line \u001b[1;32m655\u001b[0m, in \u001b[1;35mpoll\u001b[0m\n    records = self._poll_once(remaining, max_records, update_offsets=update_offsets)\n",
      "  File \u001b[1;32m\"/home/rita/anaconda3/lib/python3.9/site-packages/kafka/consumer/group.py\"\u001b[0m, line \u001b[1;32m708\u001b[0m, in \u001b[1;35m_poll_once\u001b[0m\n    records, _ = self._fetcher.fetched_records(max_records, update_offsets=update_offsets)\n",
      "  File \u001b[1;32m\"/home/rita/anaconda3/lib/python3.9/site-packages/kafka/consumer/fetcher.py\"\u001b[0m, line \u001b[1;32m344\u001b[0m, in \u001b[1;35mfetched_records\u001b[0m\n    self._next_partition_records = self._parse_fetched_data(completion)\n",
      "  File \u001b[1;32m\"/home/rita/anaconda3/lib/python3.9/site-packages/kafka/consumer/fetcher.py\"\u001b[0m, line \u001b[1;32m818\u001b[0m, in \u001b[1;35m_parse_fetched_data\u001b[0m\n    unpacked = list(self._unpack_message_set(tp, records))\n",
      "  File \u001b[1;32m\"/home/rita/anaconda3/lib/python3.9/site-packages/kafka/consumer/fetcher.py\"\u001b[0m, line \u001b[1;32m473\u001b[0m, in \u001b[1;35m_unpack_message_set\u001b[0m\n    value = self._deserialize(\n",
      "  File \u001b[1;32m\"/home/rita/anaconda3/lib/python3.9/site-packages/kafka/consumer/fetcher.py\"\u001b[0m, line \u001b[1;32m511\u001b[0m, in \u001b[1;35m_deserialize\u001b[0m\n    return f(bytes_)\n",
      "  File \u001b[1;32m\"/tmp/ipykernel_79740/2898281408.py\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<lambda>\u001b[0m\n    consumer = KafkaConsumer('trump',value_deserializer=lambda m: literal_eval(m.decode('utf8')))\n",
      "  File \u001b[1;32m\"/home/rita/anaconda3/lib/python3.9/ast.py\"\u001b[0m, line \u001b[1;32m62\u001b[0m, in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string, mode='eval')\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/rita/anaconda3/lib/python3.9/ast.py\"\u001b[0;36m, line \u001b[0;32m50\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Created date: 2022-01-06 10:29\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "consumer = KafkaConsumer('trump',value_deserializer=lambda m: literal_eval(m.decode('utf8')))\n",
    "\n",
    "for message in consumer:\n",
    "    print (message.tostring())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a89117c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7 (default, Sep 16 2021, 13:09:58) \n",
      "[GCC 7.5.0] :: Anaconda, Inc. on linux\n",
      "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
      "22/01/06 18:09:34 WARN Utils: Your hostname, EMPID21092 resolves to a loopback address: 127.0.1.1; using 192.168.43.37 instead (on interface wlp3s0)\n",
      "22/01/06 18:09:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/rita/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      ":: loading settings :: url = jar:file:/home/rita/anaconda3/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /home/rita/.ivy2/cache\n",
      "The jars for the packages stored in: /home/rita/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.11 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-eeb4781e-fa8d-453b-be89-a32ea852e8d7;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.11;2.4.4 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.0.0 in central\n",
      "\tfound org.lz4#lz4-java;1.4.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.7.3 in local-m2-cache\n",
      "\tfound org.slf4j#slf4j-api;1.7.16 in local-m2-cache\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.11/2.4.4/spark-sql-kafka-0-10_2.11-2.4.4.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.11;2.4.4!spark-sql-kafka-0-10_2.11.jar (859ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/2.0.0/kafka-clients-2.0.0.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.kafka#kafka-clients;2.0.0!kafka-clients.jar (1904ms)\n",
      "downloading https://repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar ...\n",
      "\t[SUCCESSFUL ] org.spark-project.spark#unused;1.0.0!unused.jar (176ms)\n",
      "downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.jar ...\n",
      "\t[SUCCESSFUL ] org.lz4#lz4-java;1.4.0!lz4-java.jar (435ms)\n",
      ":: resolution report :: resolve 14453ms :: artifacts dl 3387ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.kafka#kafka-clients;2.0.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.11;2.4.4 from central in [default]\n",
      "\torg.lz4#lz4-java;1.4.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.16 from local-m2-cache in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.7.3 from local-m2-cache in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   6   |   6   |   6   |   0   ||   6   |   4   |\n",
      "\t---------------------------------------------------------------------\n",
      "\n",
      ":: problems summary ::\n",
      ":::: WARNINGS\n",
      "\t\t[NOT FOUND  ] org.xerial.snappy#snappy-java;1.1.7.3!snappy-java.jar(bundle) (1ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/rita/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.3/snappy-java-1.1.7.3.jar\n",
      "\n",
      "\t\t[NOT FOUND  ] org.slf4j#slf4j-api;1.7.16!slf4j-api.jar (0ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/rita/.m2/repository/org/slf4j/slf4j-api/1.7.16/slf4j-api-1.7.16.jar\n",
      "\n",
      "\t\t::::::::::::::::::::::::::::::::::::::::::::::\n",
      "\n",
      "\t\t::              FAILED DOWNLOADS            ::\n",
      "\n",
      "\t\t:: ^ see resolution messages for details  ^ ::\n",
      "\n",
      "\t\t::::::::::::::::::::::::::::::::::::::::::::::\n",
      "\n",
      "\t\t:: org.xerial.snappy#snappy-java;1.1.7.3!snappy-java.jar(bundle)\n",
      "\n",
      "\t\t:: org.slf4j#slf4j-api;1.7.16!slf4j-api.jar\n",
      "\n",
      "\t\t::::::::::::::::::::::::::::::::::::::::::::::\n",
      "\n",
      "\n",
      "\n",
      ":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\n",
      "Exception in thread \"main\" java.lang.RuntimeException: [download failed: org.xerial.snappy#snappy-java;1.1.7.3!snappy-java.jar(bundle), download failed: org.slf4j#slf4j-api;1.7.16!slf4j-api.jar]\n",
      "\tat org.apache.spark.deploy.SparkSubmitUtils$.resolveMavenCoordinates(SparkSubmit.scala:1447)\n",
      "\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:185)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:308)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:898)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1043)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1052)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rita/anaconda3/lib/python3.9/site-packages/pyspark/python/pyspark/shell.py\", line 35, in <module>\n",
      "    SparkContext._ensure_initialized()  # type: ignore\n",
      "  File \"/home/rita/anaconda3/lib/python3.9/site-packages/pyspark/context.py\", line 339, in _ensure_initialized\n",
      "    SparkContext._gateway = gateway or launch_gateway(conf)\n",
      "  File \"/home/rita/anaconda3/lib/python3.9/site-packages/pyspark/java_gateway.py\", line 108, in launch_gateway\n",
      "    raise RuntimeError(\"Java gateway process exited before sending its port number\")\n",
      "RuntimeError: Java gateway process exited before sending its port number\n",
      ">>> "
     ]
    }
   ],
   "source": [
    "!pyspark --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204f7809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
